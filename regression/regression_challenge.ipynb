{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3 - Ames Housing Dataset Challenge <br>\n",
    "## Thomas Brewer - BOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "# Basic\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# sklearn\n",
    "from sklearn.preprocessing import StandardScaler, Imputer\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "\n",
    "# My own cleaning libraryb\n",
    "import cleaning_tools as ct\n",
    "\n",
    "# For reloading my tools, while working on them\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setting consistent seed for everything random\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/thomas/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:253: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  \"values. nan values will be ignored.\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "reload(ct)\n",
    "data = ct.make_clean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = make_clean()\n",
    "# Correlation Matrix \n",
    "corr = train.corr()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(corr)] = True\n",
    "\n",
    "f, ax = plt.subplots(figsize=(20,12))\n",
    "sns.heatmap(corr, mask=mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well there are way too many variables for this to make any sense.  Since we're focusing on SalePrice, right now, let's just show the correlations with that variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Barplot of feature correlations to SalePrice\n",
    "train = make_clean()\n",
    "predictors = [c for c in train.columns if c not in ['SalePrice', 'Id', 'PID']]\n",
    "\n",
    "corr = train.corr()\n",
    "\n",
    "f, ax = plt.subplots(figsize=(15,5))\n",
    "corr.plot(x = corr.columns, y='SalePrice', kind='bar', ax=ax)\n",
    "ax.set_ylabel('Correlation to Sale Price')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Only look at features with a correlation of abs(0.3) or higher :\n",
    "train = make_clean(del_corr=0.3)\n",
    "predictors = [c for c in train.columns if c not in ['SalePrice', 'Id', 'PID']]\n",
    "\n",
    "corr = train.corr()\n",
    "\n",
    "f, ax = plt.subplots(figsize=(15,5))\n",
    "corr.plot(x = corr.columns, y='SalePrice', kind='bar', ax=ax)\n",
    "ax.set_ylabel('Correlation to Sale Price')\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It got rid of Pool.... =("
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can take a look at some plots with highly correlated features :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = make_clean()\n",
    "\n",
    "f, [(ax1, ax2), (ax3, ax4)] = plt.subplots(nrows=2, ncols=2, figsize=(15,15), sharey=True)\n",
    "sns.boxplot(x='Overall_Qual', y='SalePrice', data=train, ax=ax1)\n",
    "sns.regplot(x='Gr_Liv_Area', y='SalePrice', data=train, ax=ax2)\n",
    "sns.regplot(x='Garage_Area', y='SalePrice', data=train, ax=ax3)\n",
    "sns.regplot(x='1st_Flr_SF', y='SalePrice', data=train, ax=ax4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Picking Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predictors(df):\n",
    "    p = []\n",
    "    for k, v in df.corr()['SalePrice'].items():\n",
    "        if k in ['Id', 'PID', 'SalePrice']:\n",
    "            print(k)\n",
    "#         if (k not in ['Id', 'PID', 'SalePrice']):\n",
    "#             p.append(k) \n",
    "\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = make_clean()\n",
    "X = train[predictors(train)]\n",
    "X.head()\n",
    "y = train['SalePrice'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=seed, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = load_data()\n",
    "print(train.shape)\n",
    "\n",
    "train = make_clean()\n",
    "print(train.shape)\n",
    "\n",
    "X = train[predictors(train)]\n",
    "print(X.shape)\n",
    "\n",
    "print(len(predictors(train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are still a lot of null values.  I need to see which ones have null values specifially and whether or not\n",
    "they're numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for k,v in train.isnull().sum().items():\n",
    "    if (v != 0):\n",
    "        print(k, v, type(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, good news, there are all numeric, so we can apply the same strategy when imputing.  I am not sure what the best strategy is here, so I guess I'll go with **median** for now, and maybe change it later to see if I get better results.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imputer = Imputer(strategy='median')\n",
    "X_imp = imputer.fit_transform(X)\n",
    "print(type(X_imp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(X.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = load_data()\n",
    "train['MS_Zoning']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = load_data()\n",
    "for k, v in data.isnull().sum().items():\n",
    "    if( v != 0):\n",
    "        print(k, v, type(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for c in data.columns :\n",
    "    data.fillna(data[c].mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
